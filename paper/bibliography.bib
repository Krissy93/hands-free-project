@article{Livatino2009,
abstract = {The use of 3-D stereoscopic visualization may provide a user with higher comprehension of remote environments in teleoperation when compared with 2-D viewing, in particular, a higher perception of environment depth characteristics, spatial localization, remote ambient layout, faster system learning, and decision performance. Works in the paper have demonstrated how stereo vision contributes to the improvement of the perception of some depth cues, often for abstract tasks, while it is hard to find works addressing stereoscopic visualization in mobile robot teleguide applications. This paper intends to contribute to this aspect by investigating the stereoscopic robot teleguide under different conditions, including typical navigation scenarios and the use of synthetic and real images. This paper also investigates how user performance may vary when employing different display technologies. Results from a set of test trials run on seven virtual reality systems, from laptop to large panorama and from head-mounted display to Cave automatic virtual environment (CAVE), emphasized few aspects that represent a base for further investigations as well as a guide when designing specific systems for telepresence. {\textcopyright} 2009 IEEE.},
author = {Livatino, Salvatore and Muscato, Giovanni and Privitera, Filippo},
doi = {10.1109/TRO.2009.2028765},
file = {:home/abel/Documenti/Mendeley Desktop/Livatino, Muscato, Privitera/IEEE Transactions on Robotics/Livatino, Muscato, Privitera - 2009 - Stereo viewing and virtual reality technologies in mobile robot teleguide.pdf:pdf},
issn = {15523098},
journal = {IEEE Trans. Robot.},
keywords = {3-D displays,Stereo vision,Teleoperation,Telerobotics,Virtual reality},
number = {6},
pages = {1343--1355},
title = {{Stereo viewing and virtual reality technologies in mobile robot teleguide}},
volume = {25},
year = {2009}
}

@article{Hokayem2006,
abstract = {This survey addresses the subject of bilateral teleoperation, a research stream with more than 50 years of history and one that continues to be a fertile ground for theoretical exploration and many applications. We focus on the control theoretic approaches that have been developed to address inherent control problems such as delays and information loss. Exposure to several concurrent applications is provided, and possible future trends are outlined. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Hokayem, Peter F. and Spong, Mark W.},
doi = {10.1016/j.automatica.2006.06.027},
file = {:home/abel/Documenti/Mendeley Desktop/Hokayem, Spong/Automatica/Hokayem, Spong - 2006 - Bilateral teleoperation An historical survey.pdf:pdf},
isbn = {0001405101},
issn = {00051098},
journal = {Automatica},
keywords = {Passivity,Passivity-based control,Robot control,Robotic manipulators,Scattering theory,Teleoperation,Telerobotics},
number = {12},
pages = {2035--2057},
title = {{Bilateral teleoperation: An historical survey}},
volume = {42},
year = {2006}
}

@article{Peppoloni2015,
abstract = {The development of natural interfaces for human-robot interaction provides the user an intuitive way to control and guide robots. In this paper, we propose a novel ROS (Robot Operating System)-integrated interface for remote control that allows the user to teleoperate the robot using his hands motion. The user can adjust online the autonomy of the robot between two levels: direct control and waypoint following. The hand tracking and gestures recognition capabilities of the Leap Motion device are exploited to generate the control commands. The user receives a real-time 3D augmented visual feedback using a Kinect sensor and a HMD. To assess the practicability of the system experimental results are presented using as a benchmark the remote control of a Kuka Youbot.},
author = {Peppoloni, Lorenzo and Brizzi, Filippo and Avizzano, Carlo Alberto and Ruffaldi, Emanuele},
doi = {10.1109/3DUI.2015.7131758},
file = {:home/abel/Documenti/Mendeley Desktop/Peppoloni et al/2015 IEEE Symposium on 3D User Interfaces, 3DUI 2015 - Proceedings/Peppoloni et al. - 2015 - Immersive ROS-integrated framework for robot teleoperation.pdf:pdf},
isbn = {9781467368865},
journal = {2015 IEEE Symp. 3D User Interfaces, 3DUI 2015 - Proc.},
keywords = {3D Interaction,augmented reality,gesture},
pages = {177--178},
publisher = {IEEE},
title = {{Immersive ROS-integrated framework for robot teleoperation}},
year = {2015}
}

@article{Kofman2005,
abstract = {Remote teleoperation of a robot manipulator by a human operator is often necessary in unstructured dynamic environments when human presence at the robot site is undesirable. Mechanical and other contacting interfaces used in teleoperation require unnatural human motions for object manipulation tasks or they may hinder human motion. Previous vision-based approaches have used only a few degrees of freedom for hand motion and have required hand motions that are unnatural for object manipulation tasks. This paper presents a noncontacting vision-based method of robot teleoperation that allows a human operator to communicate simultaneous six-degree-of-freedom motion tasks to a robot manipulator by having the operator perform the three-dimensional human hand-arm motion that would naturally be used to complete an object manipulation task. A vision-based human-robot interface is used for communication of human motion to the robot and for feedback of the robot motion and environment to the human operator. Teleoperation under operator position control was performed with high accuracy in object placement on a target. Semi-autonomous traded and shared control using robot-vision guidance aided in achieving a more accurate positioning and orientation of the end-effector for object gripping tasks. {\textcopyright} 2005 IEEE.},
author = {Kofman, Jonathan and Wu, Xianghai and Luu, Timothy and Verma, Siddharth},
doi = {10.1109/TIE.2005.855696},
file = {:home/abel/Documenti/Mendeley Desktop/Kofman et al/IEEE Transactions on Industrial Electronics/Kofman et al. - 2005 - Teleoperation of a robot manipulator using a vision-based human-robot interface.pdf:pdf},
issn = {02780046},
journal = {IEEE Trans. Ind. Electron.},
keywords = {Human-robot interface,Real time,Robot manipulator,Semi-autonomous control,Teleoperation,Traded and shared control,Vision-based tracking},
number = {5},
pages = {1206--1219},
title = {{Teleoperation of a robot manipulator using a vision-based human-robot interface}},
volume = {52},
year = {2005}
}

@article{Rebelo2014,
abstract = {Teleoperation systems are used when human planning and decision-making capabilities are needed during robotic remote operations. To execute meaningful tasks remotely, the operator has to be able to simultaneously control multiple degrees of freedom (DoFs) of the slave robot and efficiently receive information from the remote site. In these cases, haptic feedback has been shown to improve the operator's task execution performance [1].},
author = {Rebelo, Joao and Sednaoui, Thomas and {Den Exter}, Emiel Boudewijn and Krueger, Thomas and Schiele, Andre},
doi = {10.1109/MRA.2014.2360308},
file = {:home/abel/Documenti/Mendeley Desktop/Rebelo et al/IEEE Robotics and Automation Magazine/Rebelo et al. - 2014 - Bilateral robot teleoperation A wearable arm exoskeleton featuring an intuitive user interface.pdf:pdf},
issn = {10709932},
journal = {IEEE Robot. Autom. Mag.},
number = {4},
pages = {62--69},
title = {{Bilateral robot teleoperation: A wearable arm exoskeleton featuring an intuitive user interface}},
volume = {21},
year = {2014}
}

@article{Vogel2011,
abstract = {In this paper we describe and practically demonstrate a robotic arm/hand system that is controlled in real-time in 6D Cartesian space through measured human muscular activity. The soft-robotics control architecture of the robotic system ensures safe physical human robot interaction as well as stable behaviour while operating in an unstructured environment. Muscular control is realised via surface electromyography, a non-invasive and simple way to gather human muscular activity from the skin. A standard supervised machine learning system is used to create a map from muscle activity to hand position, orientation and grasping force which then can be evaluated in real time - the existence of such a map is guaranteed by gravity compensation and low-speed movement. No kinematic or dynamic model of the human arm is necessary, which makes the system quickly adaptable to anyone. Numerical validation shows that the system achieves good movement precision. Live evaluation and demonstration of the system during a robotic trade fair is reported and confirms the validity of the approach, which has potential applications in muscle-disorder rehabilitation or in teleoperation where a close-range, safe master/slave interaction is required, and/or when optical/magnetic position tracking cannot be enforced.},
author = {Vogel, J. and Castellini, C. and van der Smagt, P.},
doi = {10.1109/iros.2011.6094739},
file = {:home/abel/Documenti/Mendeley Desktop/Vogel, Castellini, van der Smagt/Unknown/Vogel, Castellini, van der Smagt - 2011 - EMG-based teleoperation and manipulation with the DLR LWR-III.pdf:pdf},
isbn = {9781612844565},
pages = {672--678},
title = {{EMG-based teleoperation and manipulation with the DLR LWR-III}},
year = {2011}
}

@article{Lv2006,
abstract = {It is a friendly human-machine interaction to operate the robot using data glove. In this paper, EON is taken as platform, virtual robot and virtual environment is set up according the real scenery. The virtual robot is the agent of remote robot in the virtual environment. Data glove is used to operate the virtual robot to complete the control towards the remote robot. Operator transmits instruction to remote controller through making use of WLAN to build up high speed, broad band correspondence network. In the Visual C++ environment, WINSOCK control widget is applied to program to carry out network correspondence which is built on foundation of the TCP/IP. {\textcopyright} 2006 IEEE.},
author = {Lv, Xiaoling and Zhang, Minglu and Cui, Feng and Zhang, Xiaoli},
doi = {10.1109/ICAT.2006.124},
file = {:home/abel/Documenti/Mendeley Desktop/Lv et al/Proceedings - 16th International Conference on Artificial Reality and Telexistence - Workshops, ICAT 2006/Lv et al. - 2006 - Teleoperation of robot based on virtual reality.pdf:pdf},
isbn = {076952754X},
journal = {Proc. - 16th Int. Conf. Artif. Real. Telexistence - Work. ICAT 2006},
pages = {400--403},
title = {{Teleoperation of robot based on virtual reality}},
year = {2006}
}

@article{Yanco2002,
abstract = {This paper integrates research and ideas in the fields of Human-Computer Interaction and Robotics for the creation of a taxonomy for human-robot interaction. By drawing from multiple research fields, a more complete taxonomy is attained. Taxonomy categories include team composition (ratio of people to robots, types of robots), amount of required interaction, decision support provided for the user, and space-time location.},
author = {Yanco, Holly A and Drury, Jill L},
file = {:home/abel/Documenti/Mendeley Desktop/Yanco, Drury/Engineering/Yanco, Drury - 2002 - A Taxonomy for Human-Robot Interaction.pdf:pdf},
journal = {Engineering},
pages = {9},
title = {{A Taxonomy for Human-Robot Interaction}},
year = {2002}
}

@article{Ajili2017,
abstract = {Interactive robotics is a vast and expanding research field. Interactions must be sufficiently natural, with robots having socially acceptable behavior by Humans, adaptable to user expectations. Thus allowing easy integration in our daily lives in various fields (science, industry, health, etc). Natural interaction during Human-Robot collaborative action needs suitable interaction techniques. In our paper we develop a gesture recognition system for natural and intuitive communication between Human and NAO robot. However recognizing meaningful gesture patterns from whole-body gestures is a complex task. That is why we used the Laban Movement Analysis technique to describe high level gestures for NAO tele-operation. The major contributions of the present work is: (1) an efficient preprocessing step based on view invariant Human motion, (2) a robust descriptor vector based on Laban Movement Analysis technique in order to generate compact and informative representations of Human movement, and (3) a gesture recognition system based on Hidden Markov Model method was applied to teleoperate NAO based on our proper database dedicated to the tele-operation of NAO. Our approach was evaluated with two challenging datasets, Microsoft Research Cambridge-12 (MSRC-12) and UTKinect-Action. Experimental results show that our approach outperforms the state-of-the-art methods.},
author = {Ajili, Insaf and Mallem, Malik and Didier, Jean Yves},
doi = {10.1109/ROMAN.2017.8172443},
file = {:home/abel/Documenti/Mendeley Desktop/Ajili, Mallem, Didier/RO-MAN 2017 - 26th IEEE International Symposium on Robot and Human Interactive Communication/Ajili, Mallem, Didier - 2017 - Gesture recognition for humanoid robot teleoperation.pdf:pdf},
isbn = {9781538635186},
journal = {RO-MAN 2017 - 26th IEEE Int. Symp. Robot Hum. Interact. Commun.},
keywords = {Detecting and Understanding Human Activity,Machine},
pages = {1115--1120},
title = {{Gesture recognition for humanoid robot teleoperation}},
volume = {2017-Janua},
year = {2017}
}

@article{Hassan2019,
abstract = {The primary purpose of this research is to move a 5-DoF Aideepen ROT3U robotic arm in real-time based on the surface Electromyography (sEMG) signal obtained from a wireless Myo gesture armband to distinguish seven hand movements. The pattern recognition system is employed to analyze these gestures and consists of three main parts: segmentation, feature extraction, and classification. Overlap technique is chosen for segmenting portion of the signal. Six-time domain features, namely, Mean Absolute Value (MAV), Waveform Length (WL), Root Mean Square (RMS), Autoregressive Coefficients (AR), Zero Crossings (ZC), Slope Sign Changes (SSC) are extracted from each segment. While the Support Vector Machines (SVM), Linear Discriminant Analysis (LDA), and K-Nearest Neighbor (K-NN) classifiers are employed in the classification of the seven hand movements. Moreover, a comparison between their performance is carried out to obtain optimum accuracy. The proposed system is tested on datasets extracted from six healthy subjects and the results showed that the SVM achieved higher system accuracy with 95.26{\%} compared to LDA with an accuracy of 92.58{\%}, and 86.41{\%} accuracy achieved by K-NN.},
archivePrefix = {arXiv},
arxivId = {1810.09929},
author = {Hassan, Hussein F. and Abou-Loukh, Sadiq J. and Ibraheem, Ibraheem Kasim},
doi = {10.1016/j.jksues.2019.05.001},
eprint = {1810.09929},
file = {:home/abel/Documenti/Mendeley Desktop/Hassan, Abou-Loukh, Ibraheem/Journal of King Saud University - Engineering Sciences/Hassan, Abou-Loukh, Ibraheem - 2019 - Teleoperated robotic arm movement using electromyography signal with wearable Myo armband.pdf:pdf},
issn = {10183639},
journal = {J. King Saud Univ. - Eng. Sci.},
keywords = {Due Arduino,Electromyography signal,Myo gesture armband,Pattern recognition,Robotic arm},
number = {xxxx},
publisher = {King Saud University},
title = {{Teleoperated robotic arm movement using electromyography signal with wearable Myo armband}},
url = {https://doi.org/10.1016/j.jksues.2019.05.001},
year = {2019}
}

@article{Hedayati2018,
abstract = {Robot teleoperation can be a challenging task, often requiring a great deal of user training and expertise, especially for platforms with high degrees-of-freedom (e.g., industrial manipulators and aerial robots). Users often struggle to synthesize information robots collect (e.g., a camera stream) with contextual knowledge of how the robot is moving in the environment. We explore how advances in augmented reality (AR) technologies are creating a new design space for mediating robot teleoperation by enabling novel forms of intuitive, visual feedback. We prototype several aerial robot teleoperation interfaces using AR, which we evaluate in a 48-participant user study where participants completed an environmental inspection task. Our new interface designs provided several objective and subjective performance benefits over existing systems, which often force users into an undesirable paradigm that divides user attention between monitoring the robot and monitoring the robots camera feed(s).},
author = {Hedayati, Hooman and Walker, Michael and Szafir, Daniel},
doi = {10.1145/3171221.3171251},
file = {:home/abel/Documenti/Mendeley Desktop/Hedayati, Walker, Szafir/ACMIEEE International Conference on Human-Robot Interaction/Hedayati, Walker, Szafir - 2018 - Improving Collocated Robot Teleoperation with Augmented Reality.pdf:pdf},
isbn = {9781450349536},
issn = {21672148},
journal = {ACM/IEEE Int. Conf. Human-Robot Interact.},
keywords = {Aerial photography,Aerial robots,Augmented reality,Drones,Free-flying robot,Interface design,Mixed reality,Teleoperation},
pages = {78--86},
title = {{Improving Collocated Robot Teleoperation with Augmented Reality}},
year = {2018}
}

@book{VERTUTJean,
author = {Vertut, Jean and Coeffet, Philippe Coiffet},
booktitle = {Prentice Hall},
title = {{Robot Technology; vol. 3A Teleoperation and Robotics Evolution and Development}},
url = {https://www.osti.gov/etdeweb/biblio/5720680},
year = {1986}
}

@article{Yang2018,
abstract = {Teleoperated robot systems are able to support humans to accomplish their tasks in many applications. However, the performance of teleoperation largely depends on motor functionality and human operator's skill, especially when a human operator is short of skill training. In order to adapt to various unstructured environments for the robot system and the human operator, in this paper, a teleoperation scheme using integrated tremor attenuation with a variable gain control algorithm involving surface electromyogram is proposed to achieve personalized control performance and to reduce reliance on operator's skill. For attenuating tremor, a filter based on support vector machine is developed to guarantee normal operation. This filter depends on the machine learning scheme and does not rely on a priori filter parameters. Semiphysical experiments have been performed to demonstrate the effectiveness of the proposed methods.},
author = {Yang, Chenguang and Luo, Jing and Pan, Yongping and Liu, Zhi and Su, Chun Yi},
doi = {10.1109/TSMC.2017.2694020},
file = {:home/abel/Documenti/Mendeley Desktop/Yang et al/IEEE Transactions on Systems, Man, and Cybernetics Systems/Yang et al. - 2018 - Personalized Variable Gain Control with Tremor Attenuation for Robot Teleoperation.pdf:pdf},
issn = {21682232},
journal = {IEEE Trans. Syst. Man, Cybern. Syst.},
keywords = {Personalized control,surface electromyographic (sEMG),teleoperated robot system,tremor attenuation,variable gain control},
number = {10},
pages = {1759--1770},
title = {{Personalized Variable Gain Control with Tremor Attenuation for Robot Teleoperation}},
volume = {48},
year = {2018}
}

@article{Du2012,
abstract = {This paper presents a real-time remote robot teleoperation method using markerless Kinect-based hand tracking. Using this tracking algorithm, the positions of index finger and thumb in 3D can be estimated by processing depth images from Kinect. The hand pose is used as a model to specify the pose of a real-time remote robot's end-effector. This method provides a way to send a whole task to a remote robot instead of sending limited motion commands like gesture-based approaches and this method has been tested in pick-and-place tasks. {\textcopyright} 2012 Du et al.},
author = {Du, Guanglong and Zhang, Ping and Mai, Jianhua and Li, Zeling},
doi = {10.5772/50093},
file = {:home/abel/Documenti/Mendeley Desktop/Du et al/International Journal of Advanced Robotic Systems/Du et al. - 2012 - Markerless Kinect-based hand tracking for robot teleoperation.pdf:pdf},
issn = {17298806},
journal = {Int. J. Adv. Robot. Syst.},
keywords = {Kinect,Markerless,Robot manipulator},
pages = {1--10},
title = {{Markerless Kinect-based hand tracking for robot teleoperation}},
volume = {9},
year = {2012}
}

@article{Glover2009,
author = {Glover, C. and Russell, B. and White, A. and Miller, M. and Stoytchev, A.},
file = {:home/abel/Documenti/Mendeley Desktop/Glover et al/Proceedings of the 2009 Emerging Technologies Conference (ETC), Ames, IA, USA/Glover et al. - 2009 - An effective and intuitive control interface for remote robot teleoperation with complete haptic feedback.pdf:pdf},
journal = {Proc. 2009 Emerg. Technol. Conf. (ETC), Ames, IA, USA},
title = {{An effective and intuitive control interface for remote robot teleoperation with complete haptic feedback}},
url = {http://www.ece.iastate.edu/{~}alexs/papers/ETC{\_}2009/ETC{\_}2009.pdf},
year = {2009}
}

@article{B2017,
abstract = {Evaluating the Capabilities of a Flight-Style Swarm AUV to Perform Emergent and Adaptive BehavioursThrough simulation, this paper evaluates the capabilities of the EcoSUB{\$}{\$}$\backslash$mu {\$}{\$}$\mu$, a small, low cost Autonomous Underwater Vehicle (AUV), to perform emergent and adaptive behaviours for environmental m... {\%}$\backslash$ 2018-06-05 17:13:00},
author = {B, Josie Hughes and Iida, Fumiya},
doi = {10.1007/978-3-319-64107-2},
file = {:home/abel/Documenti/Mendeley Desktop/B, Iida/Conference Towards Autonomous Robotic Systems/B, Iida - 2017 - 3D Printed Sensorized Soft Robotic.pdf:pdf},
isbn = {9783319641072},
journal = {Conf. Towar. Auton. Robot. Syst.},
keywords = {3d printing,manipulation,soft robotics},
pages = {627--636},
title = {{3D Printed Sensorized Soft Robotic}},
volume = {2},
year = {2017}
}

@article{Guzsvinecz2019,
abstract = {As the need for sensors increases with the inception of virtual reality, augmented reality and mixed reality, the purpose of this paper is to evaluate the suitability of the two Kinect devices and the Leap Motion Controller. When evaluating the suitability, the authors' focus was on the state of the art, device comparison, accuracy, precision, existing gesture recognition algorithms and on the price of the devices. The aim of this study is to give an insight whether these devices could substitute more expensive sensors in the industry or on the market. While in general the answer is yes, it is not as easy as it seems: There are significant differences between the devices, even between the two Kinects, such as different measurement ranges, error distributions on each axis and changing depth precision relative to distance.},
author = {Guzsvinecz, Tibor and Szucs, Veronika and Sik-Lanyi, Cecilia},
doi = {10.3390/s19051072},
file = {:home/abel/Documenti/Mendeley Desktop/Guzsvinecz, Szucs, Sik-Lanyi/Sensors (Switzerland)/Guzsvinecz, Szucs, Sik-Lanyi - 2019 - Suitability of the kinect sensor and leap motion controller-A literature review.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Accuracy,Gesture recognition,Human motion tracking,Human-computer interaction,Kinect,Leap motion,Precision,Suitability},
number = {5},
title = {{Suitability of the kinect sensor and leap motion controller-A literature review}},
volume = {19},
year = {2019}
}

@article{Hu2003,
abstract = {This paper presents a new visual gesture recognition method for the human-machine interface of mobile robot teleoperation. The interface uses seven static hand gestures, each of which represents an individual control command for the motion control of the remote robot. All the important aspects to develop such a interface are explored, including image acquisition, adaptive object segmentation with color image in RGB, HLS representation, morphological filtering, hand finding and labeling, and recognition with edge codes, template matching, and skeletonizing. By choosing processing methods and procedures properly, a higher ratio of correct recognition and a faster speed are achieved from the experiments.},
author = {Hu, Chao and Meng, Max Qinghu and Liu, Peter Xiaoping and Wang, Xiang},
doi = {10.1109/iros.2003.1248866},
file = {:home/abel/Documenti/Mendeley Desktop/Hu et al/IEEE International Conference on Intelligent Robots and Systems/Hu et al. - 2003 - Visual Gesture Recognition for Human-Machine Interface of Robot Teleoperation.pdf:pdf},
isbn = {0780378601},
journal = {IEEE Int. Conf. Intell. Robot. Syst.},
keywords = {Human Machine Interface,Robot teleoperation,Visual Gesture Recognition},
number = {October},
pages = {1560--1565},
title = {{Visual Gesture Recognition for Human-Machine Interface of Robot Teleoperation}},
volume = {2},
year = {2003}
}

@article{Boboc2012,
abstract = {Teleoperation means to operate a robot or a system from a distant location. Teleoperation is useful when the operating environment is dangerous, impractical or when achieving a specific vehicle for inspection environment is too expensive. Mobile robots can be considered as an example of teleoperation system because they can be remotely controlled to perform certain specific tasks. This paper is a review of existing teleoperated mobile robots and reports the current progress in this area.},
author = {Boboc, RG and Moga, H and TALABĂ, D},
file = {:home/abel/Documenti/Mendeley Desktop/Boboc, Moga, TALABĂ/Bulletin of the Transilvania University of Brasov Series I Engineering Sciences/Boboc, Moga, TALABĂ - 2012 - A Review of Current Applications in Teleoperation of Mobile Robots.pdf:pdf},
journal = {Bull. Transilv. Univ. Brasov Ser. I Eng. Sci.},
keywords = {communication,mobile robots,robot control,sensor,teleoperation,virtual reality},
number = {54},
pages = {9--16},
title = {{A Review of Current Applications in Teleoperation of Mobile Robots}},
volume = {5},
year = {2012}
}

@inproceedings{Roveda2018a,
abstract = {Human-robot cooperation is increasingly de- manded in industrial applications or rehabilitation tasks where a physical interaction between human and the robot is required. Many tasks require the robot to enhance the capabilities of humans, allowing them to execute onerous tasks improving their functionalities. Standard industrial manipulators are common solutions adopted to empower humans. The paper describes a fuzzy-impedance control based approach to assist human operator in industrial applications such as executing onerous tasks. The developed method allows to set in real-time the set-point of impedance controller based on human intentions. Two fuzzy member- ship functions have been defined, respectively, on the basis of force derivative and velocity signals. Such membership functions allow to on-line calculate an assistance level through the task execution, deforming the impedance control set-point to enhance the capabilities of human operator. The proposed method has been verified through an experimental procedure where several human subjects interact with the manipulator (KUKA iiwa 14 R820) to lift a heavy component while comparing the developed control strategy with the robot standard impedance controller. Experimental results show the capabilities of the designed control strategy empow- ering the human operator. Moreover, an industrial task has been performed related to the H2020 CleanSky2 EURECA project.},
author = {Roveda, Loris and Haghshenas, Shaghavezh and Prini, Alessio and Dinon, Tito and Pedrocchi, Nicola and Braghin, Francesco and Tosatti, Lorenzo Molinari},
booktitle = {2018 15th Int. Conf. Ubiquitous Robot. UR 2018},
doi = {10.1109/URAI.2018.8441800},
file = {:home/abel/Documenti/Mendeley Desktop/Roveda et al/2018 15th International Conference on Ubiquitous Robots, UR 2018/Roveda et al. - 2018 - Fuzzy Impedance Control for Enhancing Capabilities of Humans in Onerous Tasks Execution.pdf:pdf},
isbn = {9781538663349},
month = {aug},
pages = {406--411},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Fuzzy Impedance Control for Enhancing Capabilities of Humans in Onerous Tasks Execution}},
year = {2018}
}

@article{Walker2019,
abstract = {Teleoperation remains a dominant control paradigm for human interaction with robotic systems. However, teleoperation can be quite challenging, especially for novice users. Even experienced users may face difficulties or inefficiencies when operating a robot with unfamiliar and/or complex dynamics, such as industrial manipulators or aerial robots, as teleoperation forces users to focus on low-level aspects of robot control, rather than higher level goals regarding task completion, data analysis, and problem solving. We explore how advances in augmented reality (AR) may enable the design of novel teleoperation interfaces that increase operation effectiveness, support the user in conducting concurrent work, and decrease stress. Our key insight is that AR may be used in conjunction with prior work on predictive graphical interfaces such that a teleoperator controls a virtual robot surrogate, rather than directly operating the robot itself, providing the user with foresight regarding where the physical robot will end up and how it will get there. We present the design of two AR interfaces using such a surrogate: one focused on real-time control and one inspired by waypoint delegation. We compare these designs against a baseline teleoperation system in a laboratory experiment in which novice and expert users piloted an aerial robot to inspect an environment and analyze data. Our results revealed that the augmented reality prototypes provided several objective and subjective improvements, demonstrating the promise of leveraging AR to improve human-robot interactions.},
author = {Walker, Michael E. and Hedayati, Hooman and Szafir, Daniel},
doi = {10.1109/HRI.2019.8673306},
file = {:home/abel/Documenti/Mendeley Desktop/Walker, Hedayati, Szafir/ACMIEEE International Conference on Human-Robot Interaction/Walker, Hedayati, Szafir - 2019 - Robot Teleoperation with Augmented Reality Virtual Surrogates.pdf:pdf},
isbn = {9781538685556},
issn = {21672148},
journal = {ACM/IEEE Int. Conf. Human-Robot Interact.},
keywords = {ARHMD,Robots,aerial robots,augmented reality,drones,interface design,mixed reality,teleoperation},
pages = {202--210},
publisher = {IEEE},
title = {{Robot Teleoperation with Augmented Reality Virtual Surrogates}},
volume = {2019-March},
year = {2019}
}

@inproceedings{cao2018openpose,
  author = {Zhe Cao and Gines Hidalgo and Tomas Simon and Shih-En Wei and Yaser Sheikh},
  booktitle = {arXiv preprint arXiv:1812.08008},
  title = {Open{P}ose: realtime multi-person 2{D} pose estimation using {P}art {A}ffinity {F}ields},
  year = {2018}
}

@inproceedings{simon2017hand,
  author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},
  year = {2017}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@article{CameraCalib,
author={Z. {Zhang}},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={A flexible new technique for camera calibration},
year={2000},
volume={22},
number={11},
pages={1330-1334},
doi={10.1109/34.888718},
ISSN={1939-3539},
month={Nov}}

@inproceedings{CollabWork,
author="Nuzzi, Cristina
and Pasinetti, Simone
and Pagani, Roberto
and Docchio, Franco
and Sansoni, Giovanna",
editor="Cristani, Marco
and Prati, Andrea
and Lanz, Oswald
and Messelodi, Stefano
and Sebe, Nicu",
title="Hand Gesture Recognition for Collaborative Workstations: A Smart Command System Prototype",
booktitle="New Trends in Image Analysis and Processing -- ICIAP 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="332--342",
isbn="978-3-030-30754-7"
}