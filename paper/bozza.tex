%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

\overrideIEEEmargins                                      % Needed to meet printer requirements.

%In case you encounter the following error:
%Error 1010 The PDF file may be corrupt (unable to open PDF file) OR
%Error 1000 An error occurred while parsing a contents stream. Unable to analyze the PDF file.
%This is a known problem with pdfLaTeX conversion filter. The file cannot be opened with acrobat reader
%Please use one of the alternatives below to circumvent this error by uncommenting one or the other
%\pdfobjcompresslevel=0
%\pdfminorversion=4

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Hands-Free: a robot augmented reality teleoperation system
}

%\author{\authorblockN{Cristina Nuzzi\authorrefmark{1}, Stefano Ghidini\authorrefmark{2}, Roberto Pagani\authorrefmark{1}, Simone Pasinetti\authorrefmark{1} and Giovanna Sansoni\authorrefmark{1}}
%\authorblockA{\authorrefmark{1} University of Brescia, Department of Mechanical and Industrial Engineering, Via Branze 38, 25123 Brescia, Italy\\
%e-mail: c.nuzzi@unibs.it, r.pagani001@unibs.it, simone.pasinetti@unibs.it, giovanna.sansoni@unibs.it}
%\authorblockA{\authorrefmark{2} STIIMA-CNR, Via Alfonso Corti 12, 20133 Milan, Italy\\
%e-mail: stefano.ghidini@stiima.cnr.it}
%}

\author{Cristina Nuzzi$^{*}$, Stefano Ghidini, Roberto Pagani, Simone Pasinetti and Giovanna Sansoni % <-this % stops a space
\thanks{This work was not supported by any organization.}% <-this % stops a space
\thanks{Cristina Nuzzi, Roberto Pagani, Simone Pasinetti and Giovanna Sansoni are members of the Department of Mechanical and Industrial Engineering at University of Brescia, Via Branze 38, 25123 Brescia, Italy.}
\thanks{$^{*}$ Corresponding author, e-mail: {\tt\small c.nuzzi@unibs.it}}%
\thanks{Stefano Ghidini is a member of the STIIMA-CNR, Via Alfonso Corti 12, 20133 Milan, Italy. He is also a member of the Department of Mechanical and Industrial Engineering at University of Brescia, Via Branze 38, 25123 Brescia, Italy.}
}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

This electronic document is a �live� template. The various components of your paper [title, text, heads, etc.] are already defined on the style sheet, as illustrated by the portions given in this document.

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{INTRODUCTION}
Although advances in robot perception are increasing autonomous capabilities, the human intelligence is still considered a crucial need for unstructured environments with high uncertain or variability. Typical scenarios concern the detection of random shape objects, manipulation, or custom robot motion. Thus, human and robot should cooperate to achieve the same goal, defining the basis for the human-robot interaction (HRI) concept.\\
HRI can be bot physical (pHRI) or not, depending on the solution required. For instance, when the robot is constrained in a dangerous environment or must handle hazardous materials, not-pHRI is required. In this cases, robot teleoperation may be necessary. A teloperation system concerns with the exploration and exploitation of spaces which do not allow, thus, the user acts by remotely control the robot \cite{VERTUTJean;COEFFET}. A plenty of human$-$machine interfaces for teleoperation are developed considering a mechanical interface, this includes exoskeleton \cite{Rebelo2014} or gloves \cite{Lv2006}. Such systems are particularly helpful to achieve bilateral teleoperation \cite{Hokayem2006}, where they can transmit or reflect back to the user reaction forces from the task being performed. In this case, a high perception with complete haptic feedback \cite{Glover2009} is achieved. Other controllers includes joystick,  mouse,  switchbox, keyboard and touch-screen, the joystick is usually a better control device than others because the operators can identify better with the task \cite{Boboc2012}. Among the systems where bilateral teleoperation is not required, a teleoperation system is defined by mean of electromyography (EMG) signals of the muscular activity \cite{Vogel2011,Hassan2019}. However, as reminded recently in \cite{Roveda2018a}, EMG could be affected by difficulties in processing EMG signals for amplitude and spectral analysis, reducing their efficiency for many applications. Nevertheless, they still be interfaces that act by contact, hindering the movement of the operator or cause him to act through unnatural movements.\\
On the other side, if bilater interaction is not required, vision-based interfaces do not require physical contact with external devices, which means cables, connectors and unwanted objects outside of user's working area. This grant a more natural and intuitive interaction, which is reflected on task performance: in \cite{Kofman2005}, the accuracy of object gripping tasks is improved by mean of a non-contacting vision-based method of robot teleoperation; in \cite{Livatino2009} a stereo vision system improved the performance for mobile robot teleoperation.\\
Moreover, if a vision-interface is integrated with virtual and augmented reality techniques, it translates in a greater level of immersion for the user. Such techniques are used to enhance the feedback information. In fact, the operator feels like being physically present in the remote environment, enhancing the immersion level; the notion of immersion is one of the most important reasons for using virtual and augmented reality \cite{Boboc2012}.\\
In \cite{Peppoloni2015} is presented an augmented reality system for teleoperation based on Leap Motion (LP) controller. For its domain, the LP is considered an accurate sensor \cite{Hedayati2018}, however it is limited to a relatively small measuring distance if compared with other sensors. In this sense, it introduces spatial constraints that clash with the concept of high user immersion previously stated.\\
For this reasons, the following work present a novel robot augmented reality teleoperation system which exploits

.\\
BILATERAL richiesta per avere un feedback tattile (meccanico) non richiesta nel nostro caso in cui vogliamo maneggiare oggetti pericolosi.





Nella intro mettere reference al related work. Dalla intro spiegare il focus del paper e le novel contribution.

\section{DEVELOPED SYSTEM}

\subsection{Hand-Gesture Recognition}

Che rete uso, come ho impostato i gesti, lo scheletro con openpose citato, funzione per ricavare il gesto basata sull'assenza del finger, invariante dall'orientamento e dallo zoom. Immagini di esempio.

\subsection{Workspace Calibration and Mapping}

Qui spiego il problema del dover riferire i keypoints della mano ricavati nel primo workspace verde al workspace del robot per poterlo correttamente movimentare. I passi per questa procedura sono due: prima calibro il primo workspace verde rispetto a come la kinect lo inquadra, e questo sarà il workspace di riferimento. Ottengo una trasformazione pixel to realeper sapere in metri dove è posizionata la mano (i keypoints) nel workspace verde.
Poi devo riferire questo workspace verde a quello in cui si muove il robot. Per farlo devo sapere il rapporto di mapping tra il w1 e il w2, cioè a cosa corrisponde il punto 1 di w1 in w2 ecc. Poi devo fare la stessa cosa per capire qual è il riferimento del robot rispetto a w2. Per farlo devo muovere sperimentalmente il robot in diverse posizioni del master e ricavare a cosa corrispondono nel master rispetto al robot per ottenere questo mapping.
Immagini che rappresentano questa procedura.
Procedura di calibrazione automatica?

\section{EXPERIMENTS}

Due esperimenti: uno sulla ripetibilità del posizionamento del robot rispetto alla teleoperazione e uno sul posizionamento corretto del robot su un oggetto stampato in 3D per l'esperimento.
Specifiche del set-up utilizzato: rappresentazioni dei master di calibrazione usati, specifiche delle loro dimensioni, robot usato, pinza customizzata con laserino, oggetto 3D stampato.

\subsection{First experiment}

Spiegazione della procedura. Descrizione della pinza laser usata per il posizionamento accurato. Come prendo i dati? Lascio giù un segno sul master (a mano?), prendo una foto?
Risultati ottenuti.
Commento.

\subsection{Second experiment}

Descrizione della piastra 3D stampata per l'esperimento e obiettivi.
Risultati ottenuti.
Commento.


\section{USING THE TEMPLATE}

\subsection{Figures and Tables}

Positioning Figures and Tables: Place figures and tables at the top and bottom of columns. Avoid placing them in the middle of columns. Large figures and tables may span across both columns. Figure captions should be below the figures; table heads should appear above the tables. Insert figures and tables after they are cited in the text. Use the abbreviation �Fig. 1�, even at the beginning of a sentence.

\begin{table}[h]
\caption{An Example of a Table}
\label{table_example}
\begin{center}
\begin{tabular}{|c||c|}
\hline
One & Two\\
\hline
Three & Four\\
\hline
\end{tabular}
\end{center}
\end{table}


   \begin{figure}[thpb]
      \centering
      \framebox{\parbox{3in}{We suggest that you use a text box to insert a graphic (which is ideally a 300 dpi TIFF or EPS file, with all fonts embedded) because, in an document, this method is somewhat more stable than directly inserting a picture.
}}
      %\includegraphics[scale=1.0]{figurefile}
      \caption{Inductance of oscillation winding on amorphous
       magnetic core versus DC bias magnetic field}
      \label{figurelabel}
   \end{figure}
   

Figure Labels: Use 8 point Times New Roman for Figure labels. Use words rather than symbols or abbreviations when writing Figure axis labels to avoid confusing the reader. As an example, write the quantity �Magnetization�, or �Magnetization, M�, not just �M�. If including units in the label, present them within parentheses. Do not label axes only with units. In the example, write �Magnetization (A/m)� or �Magnetization {A[m(1)]}�, not just �A/m�. Do not label axes with a ratio of quantities and units. For example, write �Temperature (K)�, not �Temperature/K.�

\section{CONCLUSIONS}

Conclusioni sul progetto/esperimenti ottenuti.
Problematiche incontrate e come sono state risolte.
Future developments.

\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.
%Hands-free
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\bibliographystyle{ieeetr}
%\bibliography{/home/abel/Documenti/Mendeley_References/LuGre}


\bibliographystyle{ieeetr}
\bibliography{/home/abel/Documenti/Mendeley_References/Hands-free}


\end{document}
